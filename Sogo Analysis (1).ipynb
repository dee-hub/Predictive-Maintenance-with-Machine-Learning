{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(os.getcwd(), './CMAPSSData')\n",
    "print(os.listdir(dir_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['unit_nr', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i) for i in range(1,22)] \n",
    "col_names = index_names + setting_names + sensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv((dir_path+'/train_FD001.txt'), sep='\\s+', header=None, names=col_names)\n",
    "test = pd.read_csv((dir_path+'/test_FD001.txt'), sep='\\s+', header=None, names=col_names)\n",
    "y_test = pd.read_csv((dir_path+'/RUL_FD001.txt'), sep='\\s+', header=None, names=['RUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[index_names].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data, it is seen that the dataset contains simulations on 100 turbofan engines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[index_names].groupby('unit_nr').max().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting the max time_cycles you can see the engine which failed the earliest did so after 128 cycles, whereas the engine which operated the longest broke down after 362 cycles. The average engine breaks between 199 and 206 cycles, however the standard deviation of 46 cycles is rather big. The standard deviation means the space of failure between any two different engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[setting_names].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[sensor_names].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the standard deviation it’s clear sensors 1, 10, 18 and 19 do not fluctuate at all, these can be safely discarded as they hold no useful information. Inspecting the quantiles indicates sensors 5, 6 and 16 have little fluctuation and require further inspection. Sensors 9 and 14 have the highest fluctuation, however this does not mean the other sensors can’t hold valuable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the data distribution of our data, we can compute the RUL (Remaining Useful Life) of the engine, which will give us an insight into how the sensor changes as the engine nears breakdown, which will also serve as the target variable of our work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However there is no set predefined way to compute the RUL for our turbofan engines one way to do that is by assuming the RUL decreases linearly over time and have a value of 0 at the last time cycle of the engine. This assumption implies RUL would be 10 at 10 cycles before breakdown, 50 at 50 cycles before breakdown, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_unit = train.groupby(by=\"unit_nr\")\n",
    "max_cycle = grouped_by_unit[\"time_cycles\"].max()\n",
    "    \n",
    "    # Merge the max cycle back into the original frame\n",
    "result_frame = train.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)\n",
    "    \n",
    "    # Calculate remaining useful life for each row\n",
    "remaining_useful_life = result_frame[\"max_cycle\"] - result_frame[\"time_cycles\"]\n",
    "result_frame[\"RUL\"] = remaining_useful_life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = result_frame.drop(\"max_cycle\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = result_frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[index_names+['RUL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_description = train.describe()\n",
    "print(dataset_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = dataset_description.T.plot.bar(subplots=True, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = train.corr()\n",
    "data_corr['RUL'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = train.copy()[setting_names + sensor_names]\n",
    "df_corr = df_plot.corr(method='pearson')\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "axes = sns.heatmap(df_corr, linewidths=.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_plot = train.copy()\n",
    "df_plot = df_plot.sort_values(index_names)\n",
    "graph = sns.PairGrid(data=df_plot, x_vars=\"RUL\", y_vars=setting_names + sensor_names, hue=\"unit_nr\", height=4, aspect=6,)\n",
    "graph = graph.map(plt.plot, alpha=0.5)\n",
    "graph = graph.set(xlim=(df_plot['RUL'].max(),df_plot['RUL'].min()))\n",
    "# graph = graph.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    return '{} set RMSE:{}, R2:{}'.format(label, rmse, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_sensors = ['s_1','s_5','s_6','s_10','s_16','s_18','s_19']\n",
    "drop_labels = index_names+setting_names+drop_sensors\n",
    "X_train = train.drop(drop_labels, axis=1)\n",
    "y_train = X_train.pop('RUL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.groupby('unit_nr').last().reset_index().drop(drop_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    train_pred_lin = lin_reg.predict(X_train)\n",
    "    test_pred_lin = lin_reg.predict(X_test)\n",
    "    result_train = evaluate(y_train, train_pred_lin, 'train')\n",
    "    result_test = evaluate(y_train, train_pred_lin)\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    dec_tree = DecisionTreeRegressor()\n",
    "    dec_tree.fit(X_train, y_train)\n",
    "    train_pred_dec = dec_tree.predict(X_train)\n",
    "    test_pred_dec = dec_tree.predict(X_test)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    ran_forest = RandomForestRegressor()\n",
    "    ran_forest.fit(X_train, y_train)\n",
    "    train_pred_ran = ran_forest.predict(X_train)\n",
    "    test_pred_ran = ran_forest.predict(X_test)\n",
    "    \n",
    "    from sklearn.svm import SVR\n",
    "    svr = SVR(kernel='linear')\n",
    "    svr.fit(X_train, y_train)\n",
    "    train_pred_svr = svr.predict(X_train)\n",
    "    test_pred_svr = svr.predict(X_test)\n",
    "    \n",
    "    from sklearn.linear_model import LassoCV\n",
    "    lasso = LassoCV()\n",
    "    lasso.fit(X_train, y_train)\n",
    "    train_pred_lasso = lasso.predict(X_train)\n",
    "    test_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "    \n",
    "    print('Linear Regression Results \\n', evaluate(y_train, train_pred_lin, 'train'), '\\n', evaluate(y_test, test_pred_lin), '\\n')\n",
    "    print('Decision Tree Regression Results \\n', evaluate(y_train, train_pred_dec, 'train'), '\\n', evaluate(y_test, test_pred_dec), '\\n')\n",
    "    print('Random Forest Regression Results \\n', evaluate(y_train, train_pred_ran, 'train'), '\\n', evaluate(y_test, test_pred_ran), '\\n')\n",
    "    print('Support Vector Regression Results \\n', evaluate(y_train, train_pred_svr, 'train'), '\\n', evaluate(y_test, test_pred_svr), '\\n')\n",
    "    print('Lasso Regression Results \\n', evaluate(y_train, train_pred_lasso, 'train'), '\\n', evaluate(y_test, test_pred_lasso), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing some feature engineering\n",
    "y_train_clipped = y_train.clip(upper=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model(X_train, y_train_clipped, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling our dataset\n",
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X_train_scaled, y_train_clipped, X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
